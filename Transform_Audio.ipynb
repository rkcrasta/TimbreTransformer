{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transform_Audio.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPVDAFNQjZlJvYvao0//xO8"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwaif6YT2ASq","executionInfo":{"status":"ok","timestamp":1627784254687,"user_tz":240,"elapsed":27879,"user":{"displayName":"Rohan Crasta","photoUrl":"","userId":"16238217913552262027"}},"outputId":"bc4e3ffb-c550-455e-bafc-19b14f99b63e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C5O4T-NtgonF"},"source":["#Directory of the python scripts that need to be imported - passed to sys.path.append()\n","SCRIPTS_PATH = '/content/drive/My Drive/TimbreTransformer/Scripts'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSSBRaak-axy"},"source":["#The working directory passed to os.chdir()\n","DEFAULT_PATH = '/content/drive/My Drive/TimbreTransformer'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cuAdhct-kw5"},"source":["PARAMS = {'model_name':'flute_v1', 'input_audio': 'Data/Violin.mp3', 'output_audio': 'Data/Transformed.wav'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pCmQgpk72Xpb"},"source":["import sys\n","sys.path.append(SCRIPTS_PATH)\n","import os\n","os.chdir(DEFAULT_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S1RGVBd9PI-L"},"source":["import import_audio\n","import process_audio\n","import custom_loss\n","import tensorflow as tf\n","import numpy as np\n","import model\n","import scipy\n","import scipy.io.wavfile\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAlbBHmEeuZ2"},"source":["gan = model.Model(PARAMS['model_name']).load_from_file()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEO1WgF1Pbni","executionInfo":{"status":"ok","timestamp":1627784285356,"user_tz":240,"elapsed":19980,"user":{"displayName":"Rohan Crasta","photoUrl":"","userId":"16238217913552262027"}},"outputId":"52d814ff-eac1-4376-ab0c-b40af8099321"},"source":["input_audio = import_audio.Audio(PARAMS['input_audio'], n_fft=gan.model_params['n_fft'], srate=gan.model_params['srate'], shuffle_spec = False, shuffle_audio = False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n","  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vTB0hFapS6GV"},"source":["def predict(spectrogram, generator, input_shape = (129,500,1)):\n","\n","    input, scaling = process_audio.partition(spectrogram, input_shape = input_shape)\n","\n","    model_prediction = generator.predict(input)\n","\n","    combined = np.squeeze(process_audio.combine(model_prediction, scaling))\n","\n","    return combined"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rGQOfHCEQwJy"},"source":["def spectrogram_to_audio(spec, phase, n_fft = 256, srate = 22050):\n","    \"\"\"\n","    Creates a complex valued array that will be transformed to the final audio through the inverse fourier transform\n","    The complex array has value of Spec[a,b]x(cos(phase[a,b])+i sin(phase[a,b]))\n","    \"\"\"\n","    a = spec.shape[1]\n","    b = phase.shape[1]\n","\n","    #Prevents out of bounds error if the spec and phase arrays are of different sizes by using the minimum value\n","    max_length = min(a,b)\n","    \n","    ft = np.multiply(spec[:,:max_length], np.cos(phase[:,:max_length])) + 1j*np.multiply(spec[:,:max_length], np.sin(phase[:,:max_length]))\n","\n","    audio = scipy.signal.istft(ft, fs = srate, nperseg = n_fft)[1]\n","\n","    return audio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AqjhJaV6rZoG"},"source":["data = spectrogram_to_audio(predict(spectrogram=input_audio.ft.spec, generator = gan.generator, input_shape = gan.input_shape),phase = input_audio.ft.phase, n_fft = gan.model_params['n_fft'], srate = gan.model_params['srate'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cOJa9YDcudsx"},"source":["#Scale audio to range from 0 - 1\n","data = np.divide(data, np.amax(np.abs(data)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2wHvoLnRrYpJ"},"source":["scipy.io.wavfile.write(PARAMS['output_audio'], rate = gan.model_params['srate'],  data= data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1sZ_XfYKt5_f"},"source":[""],"execution_count":null,"outputs":[]}]}